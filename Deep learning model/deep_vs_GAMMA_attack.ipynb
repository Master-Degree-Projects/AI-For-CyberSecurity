{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting drive"
      ],
      "metadata": {
        "id": "9hJzNKJ3B4zv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZBWse7DBlZM"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download dataset"
      ],
      "metadata": {
        "id": "aFRNHZzCCkDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "url = '1-CNx_k1yEJ-RDC94nXUMlhtc1FQH7lzt'\n",
        "gdown.download(id=url, output=\"test_set.tar.gz\")"
      ],
      "metadata": {
        "id": "ugrnQM-ICmAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p test\n",
        "\n",
        "!tar -zxf '/content/test_set.tar.gz' -C /content/test\n",
        "!rm '/content/test_set.tar.gz'\n",
        "\n",
        "test_path = '/content/test'"
      ],
      "metadata": {
        "id": "_g2weIsSC0Ag"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies and libraries"
      ],
      "metadata": {
        "id": "wZJv5cNyCBUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install lief==0.12.0\n",
        "!pip install numpy\n",
        "!pip install deap\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install tqdm\n",
        "!pip install python-magic\n",
        "# Install ML-Pentest Lib\n",
        "!pip install ml-pentest"
      ],
      "metadata": {
        "id": "1asSX9iyCC_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ml_pentest.attacks.blackbox.genetic_attack.GAMMA.gamma_section_injection import GammaSectionInjection\n",
        "from ml_pentest.attacks.blackbox.genetic_attack.GAMMA.attack_utils import create_section_population_from_folder\n",
        "from ml_pentest.models.wrappers.malconv2_wrapper import MalConvWrapper\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import lief\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "DhuvTrR4Dth4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models definition"
      ],
      "metadata": {
        "id": "cpfrcDtTDRNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection\n",
        "Edward Raff, William Fleshman, Richard Zak, Hyrum Anderson and Bobby Filar and Mark Mclean\n",
        "https://arxiv.org/abs/2012.09390\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def drop_zeros_hook(module, grad_input, grad_out):\n",
        "    \"\"\"\n",
        "    This function is used to replace gradients that are all zeros with None\n",
        "    In pyTorch None will not get back-propogated\n",
        "    So we use this as a approximation to saprse BP to avoid redundant and useless work\n",
        "    \"\"\"\n",
        "    grads = []\n",
        "    with torch.no_grad():\n",
        "        for g in grad_input:\n",
        "            if torch.nonzero(g).shape[0] == 0:\n",
        "                grads.append(g.to_sparse())\n",
        "            else:\n",
        "                grads.append(g)\n",
        "\n",
        "    return tuple(grads)\n",
        "\n",
        "\n",
        "class CatMod(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CatMod, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat(x, dim=2)\n",
        "\n",
        "\n",
        "class LowMemConvBase(nn.Module):\n",
        "\n",
        "    def __init__(self, chunk_size=65536, overlap=512, min_chunk_size=1024):\n",
        "        \"\"\"\n",
        "        chunk_size: how many bytes at a time to process. Increasing may improve compute efficent, but use more memory. Total memory use will be a function of chunk_size, and not of the length of the input sequence L\n",
        "\n",
        "        overlap: how many bytes of overlap to use between chunks\n",
        "\n",
        "        \"\"\"\n",
        "        super(LowMemConvBase, self).__init__()\n",
        "        self.chunk_size = chunk_size\n",
        "        self.overlap = overlap\n",
        "        self.min_chunk_size = min_chunk_size\n",
        "\n",
        "        #Used for pooling over time in a more efficent way\n",
        "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.cat = CatMod()\n",
        "        self.cat.register_backward_hook(drop_zeros_hook)\n",
        "        self.receptive_field = None\n",
        "\n",
        "        #Used to force checkpoint code to behave correctly due to poor design https://discuss.pytorch.org/t/checkpoint-with-no-grad-requiring-inputs-problem/19117/11\n",
        "        self.dummy_tensor = torch.ones(1, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    def processRange(self, x, **kwargs):\n",
        "        \"\"\"\n",
        "        This method does the work to convert an LongTensor input x of shape (B, L) , where B is the batch size and L is the length of the input. The output of this functoin should be a tensor of (B, C, L), where C is the number of channels, and L is again the input length (though its OK if it got a little shorter due to convs without padding or something).\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def determinRF(self):\n",
        "        \"\"\"\n",
        "        This function evaluates the receptive field & stride of our sub-network.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.receptive_field is not None:\n",
        "            return self.receptive_field, self.stride, self.out_channels\n",
        "\n",
        "        if not hasattr(self, \"device_ids\"):\n",
        "            #We are training with just one device. Lets find out where we should move the data\n",
        "            cur_device = next(self.embd.parameters()).device\n",
        "        else:\n",
        "            cur_device = \"cpu\"\n",
        "\n",
        "        #Lets do a simple binary search to figure out how large our RF is.\n",
        "        #It can't be larger than our chunk size! So use that as upper bound\n",
        "        min_rf = 1\n",
        "        max_rf = self.chunk_size\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            tmp = torch.zeros((1,max_rf)).long().to(cur_device)\n",
        "\n",
        "            while True:\n",
        "                test_size = (min_rf+max_rf)//2\n",
        "                is_valid = True\n",
        "                try:\n",
        "                    self.processRange(tmp[:,0:test_size])\n",
        "                except:\n",
        "                    is_valid = False\n",
        "\n",
        "                if is_valid:\n",
        "                    max_rf = test_size\n",
        "                else:\n",
        "                    min_rf = test_size+1\n",
        "\n",
        "                if max_rf == min_rf:\n",
        "                    self.receptive_field = min_rf\n",
        "                    out_shape = self.processRange(tmp).shape\n",
        "                    self.stride = self.chunk_size//out_shape[2]\n",
        "                    self.out_channels = out_shape[1]\n",
        "                    break\n",
        "\n",
        "\n",
        "        return self.receptive_field, self.stride, self.out_channels\n",
        "\n",
        "\n",
        "    def pool_group(self, *args):\n",
        "        x = self.cat(args)\n",
        "        x = self.pooling(x)\n",
        "        return x\n",
        "\n",
        "    def seq2fix(self, x, pr_args={}):\n",
        "        \"\"\"\n",
        "        Takes in an input LongTensor of (B, L) that will be converted to a fixed length representation (B, C),\n",
        "        where C is the number of channels provided by the base_network given at construction.\n",
        "        \"\"\"\n",
        "\n",
        "        receptive_window, stride, out_channels = self.determinRF()\n",
        "\n",
        "        if x.shape[1] < receptive_window: #This is a tiny input! Pad it out\n",
        "            x = F.pad(x, (0, receptive_window-x.shape[1]), value=0) # 0 is the pad value\n",
        "        batch_size = x.shape[0]\n",
        "        length = x.shape[1]\n",
        "\n",
        "        #Let's go through the input data without gradients first, and find the positions that \"win\"\n",
        "        #the max-pooling. Most of the gradients will be zero, and we don't want to waste valuable\n",
        "        #memory and time computing them.\n",
        "        #Once we know the winners, we will go back and compute the forward activations on JUST\n",
        "        #the subset of positions that won!\n",
        "        winner_values = np.zeros((batch_size, out_channels))-1.0\n",
        "        winner_indices = np.zeros((batch_size, out_channels), dtype=np.int64)\n",
        "\n",
        "        if not hasattr(self, \"device_ids\"):\n",
        "            #We are training with just one device. Lets find out where we should move the data\n",
        "            cur_device = next(self.embd.parameters()).device\n",
        "        else:\n",
        "            cur_device = None\n",
        "\n",
        "        step = self.chunk_size #- self.overlap\n",
        "        start = 0\n",
        "        end = start+step\n",
        "\n",
        "        with torch.no_grad():\n",
        "            while start < end and (end-start) >= max(self.min_chunk_size, receptive_window):\n",
        "                x_sub = x[:,start:end]\n",
        "                if cur_device is not None:\n",
        "                    x_sub = x_sub.to(cur_device)\n",
        "                activs = self.processRange(x_sub.long(), **pr_args)\n",
        "                activ_win, activ_indx = F.max_pool1d(activs, kernel_size=activs.shape[2], return_indices=True)\n",
        "                #We want to remove only last dimension, but if batch size is 1, np.squeeze\n",
        "                #will screw us up and remove first dim too.\n",
        "                #activ_win = np.squeeze(activ_win.cpu().numpy())\n",
        "                #activ_indx = np.squeeze(activ_indx.cpu().numpy())\n",
        "                activ_win = activ_win.cpu().numpy()[:,:,0]\n",
        "                activ_indx = activ_indx.cpu().numpy()[:,:,0]\n",
        "                selected = winner_values < activ_win\n",
        "                winner_indices[selected] = activ_indx[selected]*stride + start\n",
        "                winner_values[selected]  = activ_win[selected]\n",
        "                start = end\n",
        "                end = min(start+step, length)\n",
        "\n",
        "        # Now we know every index that won, we need to compute values and with gradients!\n",
        "\n",
        "        # Find unique winners for every batch\n",
        "        final_indices = [np.unique(winner_indices[b,:]) for b in range(batch_size)]\n",
        "\n",
        "        # Collect inputs that won for each batch\n",
        "        chunk_list = [[x[b:b+1,max(i-receptive_window,0):min(i+receptive_window,length)] for i in final_indices[b]] for b in range(batch_size)]\n",
        "        # Convert to a torch tensor of the bytes\n",
        "        chunk_list = [torch.cat(c, dim=1)[0,:] for c in chunk_list]\n",
        "\n",
        "        # Pad out shorter sequences to the longest one\n",
        "        x_selected = torch.nn.utils.rnn.pad_sequence(chunk_list, batch_first=True)\n",
        "\n",
        "        # Shape is not (B, L). Compute it.\n",
        "        if cur_device is not None:\n",
        "            x_selected = x_selected.to(cur_device)\n",
        "        x_selected = self.processRange(x_selected.long(), **pr_args)\n",
        "        x_selected = self.pooling(x_selected)\n",
        "        x_selected = x_selected.view(x_selected.size(0), -1)\n",
        "\n",
        "        return x_selected\n"
      ],
      "metadata": {
        "id": "D7eAvaq9DVdh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MalConv"
      ],
      "metadata": {
        "id": "QJt2K4lgDZR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MalConv(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, embd_size=8, log_stride=None):\n",
        "        super(MalConv, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        if not log_stride is None:\n",
        "            stride = 2**log_stride\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "        self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "\n",
        "    def processRange(self, x):\n",
        "        x = self.embd(x)\n",
        "        x = torch.transpose(x,-1,-2)\n",
        "\n",
        "        cnn_value = self.conv_1(x)\n",
        "        gating_weight = torch.sigmoid(self.conv_2(x))\n",
        "\n",
        "        x = cnn_value * gating_weight\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "\n",
        "        penult = x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class MalConvML(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, layers=1, embd_size=8, log_stride=None):\n",
        "        super(MalConvML, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        if not log_stride is None:\n",
        "            stride = 2**log_stride\n",
        "\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(embd_size, channels*2, window_size, stride=stride, bias=True)] + [nn.Conv1d(channels, channels*2, window_size, stride=1, bias=True) for i in range(layers-1)])\n",
        "        #one-by-one cons to perform information sharing\n",
        "        self.convs_1 = nn.ModuleList([nn.Conv1d(channels, channels, 1, bias=True) for i in range(layers)])\n",
        "\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "\n",
        "    def processRange(self, x):\n",
        "        x = self.embd(x)\n",
        "        #x = torch.transpose(x,-1,-2)\n",
        "        x = x.permute(0,2,1).contiguous()\n",
        "\n",
        "        for conv_glu, conv_share in zip(self.convs, self.convs_1):\n",
        "            x = F.leaky_relu(conv_share(F.glu(conv_glu(x.contiguous()), dim=1)))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "\n",
        "        penult = x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return x, penult, post_conv"
      ],
      "metadata": {
        "id": "zeInRnzZDapU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MalConv2"
      ],
      "metadata": {
        "id": "UFo4ZQb1DcHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection\n",
        "Edward Raff, William Fleshman, Richard Zak, Hyrum Anderson and Bobby Filar and Mark Mclean\n",
        "https://arxiv.org/abs/2012.09390\n",
        "\n",
        "Taken from https://github.com/NeuromorphicComputationResearchProgram/MalConv2\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MalConv2(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, embd_size=8, log_stride=None):\n",
        "        super(MalConv2, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        if not log_stride is None:\n",
        "            stride = 2**log_stride\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "        self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "\n",
        "    def processRange(self, x):\n",
        "        x = self.embd(x)\n",
        "        x = torch.transpose(x,-1,-2)\n",
        "\n",
        "        cnn_value = self.conv_1(x)\n",
        "        gating_weight = torch.sigmoid(self.conv_2(x))\n",
        "\n",
        "        x = cnn_value * gating_weight\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "\n",
        "        penult = x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "78N3IHW5DdRU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MalConvGCG"
      ],
      "metadata": {
        "id": "oouziKMzDfc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection\n",
        "Edward Raff, William Fleshman, Richard Zak, Hyrum Anderson and Bobby Filar and Mark Mclean\n",
        "https://arxiv.org/abs/2012.09390\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "\n",
        "class MalConvGCG(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, layers=1, embd_size=8, log_stride=None, low_mem=True):\n",
        "        super(MalConvGCG, self).__init__()\n",
        "        self.low_mem = low_mem\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        if not log_stride is None:\n",
        "            stride = 2**log_stride\n",
        "\n",
        "        self.context_net = MalConvML(out_size=channels, channels=channels, window_size=window_size, stride=stride, layers=layers, embd_size=embd_size)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(embd_size, channels*2, window_size, stride=stride, bias=True)] + [nn.Conv1d(channels, channels*2, window_size, stride=1, bias=True) for i in range(layers-1)])\n",
        "\n",
        "        #These two objs are not used. They were originally present before the F.glu function existed, and then were accidently left in when we switched over. So the state file provided has unusued states in it. They are left in this definition so that there are no issues loading the file that MalConv was trained on.\n",
        "        #If you are going to train from scratch, you can delete these two lines.\n",
        "        #self.convs_1 = nn.ModuleList([nn.Conv1d(channels*2, channels, 1, bias=True) for i in range(layers)])\n",
        "        #self.convs_atn = nn.ModuleList([nn.Conv1d(channels*2, channels, 1, bias=True) for i in range(layers)])\n",
        "\n",
        "        self.linear_atn = nn.ModuleList([nn.Linear(channels, channels) for i in range(layers)])\n",
        "\n",
        "        #one-by-one cons to perform information sharing\n",
        "        self.convs_share = nn.ModuleList([nn.Conv1d(channels, channels, 1, bias=True) for i in range(layers)])\n",
        "\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "\n",
        "    #Over-write the determinRF call to use the base context_net to detemrin RF. We should have the same totla RF, and this will simplify logic significantly.\n",
        "    def determinRF(self):\n",
        "        return self.context_net.determinRF()\n",
        "\n",
        "    def processRange(self, x, gct=None):\n",
        "        if gct is None:\n",
        "            raise Exception(\"No Global Context Given\")\n",
        "\n",
        "        x = self.embd(x)\n",
        "        #x = torch.transpose(x,-1,-2)\n",
        "        x = x.permute(0,2,1)\n",
        "\n",
        "        for conv_glu, linear_cntx, conv_share in zip(self.convs, self.linear_atn, self.convs_share):\n",
        "            x = F.glu(conv_glu(x), dim=1)\n",
        "            x = F.leaky_relu(conv_share(x))\n",
        "            x_len = x.shape[2]\n",
        "            B = x.shape[0]\n",
        "            C = x.shape[1]\n",
        "\n",
        "            sqrt_dim = np.sqrt(x.shape[1])\n",
        "            #we are going to need a version of GCT with a time dimension, which we will adapt as needed to the right length\n",
        "            ctnx = torch.tanh(linear_cntx(gct))\n",
        "\n",
        "            #Size is (B, C), but we need (B, C, 1) to use as a 1d conv filter\n",
        "            ctnx = torch.unsqueeze(ctnx, dim=2)\n",
        "            #roll the batches into the channels\n",
        "            x_tmp = x.view(1,B*C,-1)\n",
        "            #Now we can apply a conv with B groups, so that each batch gets its own context applied only to what was needed\n",
        "            x_tmp = F.conv1d(x_tmp, ctnx, groups=B)\n",
        "            #x_tmp will have a shape of (1, B, L), now we just need to re-order the data back to (B, 1, L)\n",
        "            x_gates = x_tmp.view(B, 1, -1)\n",
        "\n",
        "            #Now we effectively apply Ïƒ(x_t^T tanh(W c))\n",
        "            gates = torch.sigmoid( x_gates )\n",
        "            x = x * gates\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.low_mem:\n",
        "            global_context = checkpoint.CheckpointFunction.apply(self.context_net.seq2fix,1, x)\n",
        "        else:\n",
        "            global_context = self.context_net.seq2fix(x)\n",
        "\n",
        "        post_conv = x = self.seq2fix(x, pr_args={'gct':global_context})\n",
        "\n",
        "        penult = x = F.leaky_relu(self.fc_1( x ))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "PuCqQRzeDzCh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AvastConv"
      ],
      "metadata": {
        "id": "g-p5xCYdD0jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def vec_bin_array(arr, m=8):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    arr: Numpy array of positive integers\n",
        "    m: Number of bits of each integer to retain\n",
        "\n",
        "    Returns a copy of arr with every element replaced with a bit vector.\n",
        "    Bits encoded as int8's.\n",
        "    \"\"\"\n",
        "    to_str_func = np.vectorize(lambda x: np.binary_repr(x).zfill(m))\n",
        "    strs = to_str_func(arr)\n",
        "    ret = np.zeros(list(arr.shape) + [m], dtype=np.int8)\n",
        "    for bit_ix in range(0, m):\n",
        "        fetch_bit_func = np.vectorize(lambda x: x[bit_ix] == '1')\n",
        "        ret[...,bit_ix] = fetch_bit_func(strs).astype(np.int8)\n",
        "\n",
        "    return (ret*2-1).astype(np.float32)/16\n",
        "\n",
        "class AvastConv(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=48, window_size=32, stride=4, embd_size=8):\n",
        "        super(AvastConv, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        for i in range(1, 257):\n",
        "            self.embd.weight.data[i,:] = torch.tensor(vec_bin_array(np.asarray([i])))\n",
        "        for param in self.embd.parameters():\n",
        "             param.requires_grad = False\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(8, channels, window_size, stride=stride, bias=True)\n",
        "        self.conv_2 = nn.Conv1d(channels, channels*2, window_size, stride=stride, bias=True)\n",
        "        self.pool = nn.MaxPool1d(4)\n",
        "        self.conv_3 = nn.Conv1d(channels*2, channels*3, window_size//2, stride=stride*2, bias=True)\n",
        "        self.conv_4 = nn.Conv1d(channels*3, channels*4, window_size//2, stride=stride*2, bias=True)\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels*4, channels*4)\n",
        "        self.fc_2 = nn.Linear(channels*4, channels*3)\n",
        "        self.fc_3 = nn.Linear(channels*3, channels*2)\n",
        "        self.fc_4 = nn.Linear(channels*2, out_size)\n",
        "\n",
        "\n",
        "    def processRange(self, x):\n",
        "        # Fixed embedding\n",
        "        with torch.no_grad():\n",
        "            x = self.embd(x)\n",
        "            x = torch.transpose(x,-1,-2)\n",
        "\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = F.relu(self.conv_2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv_3(x))\n",
        "        x = F.relu(self.conv_4(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "\n",
        "        x = F.selu(self.fc_1(x))\n",
        "        x = F.selu(self.fc_2(x))\n",
        "        penult = x = F.selu(self.fc_3(x))\n",
        "        x = self.fc_4(x)\n",
        "\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "mPwahPqxDz18"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extensive evaluation of model's robustness"
      ],
      "metadata": {
        "id": "4cjnlZtaEGX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model import"
      ],
      "metadata": {
        "id": "1r9QkLymEHWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading best models folder\n",
        "\n",
        "id = '1X8oAi1E183wHkXh4K1I8VdkefBAMS7GM'\n",
        "gdown.download_folder(id=id)"
      ],
      "metadata": {
        "id": "PoFMjsFYE5QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MalConv2(out_size=1, channels=128, window_size=500, stride=500, embd_size=8, log_stride=None)\n",
        "model.load_state_dict(torch.load(\"/content/drive/Shareddrives/AFC/models/malconv2_model.pt\"), strict=False)\n",
        "model = model.to(device)\n",
        "\n",
        "model_wrapper = MalConvWrapper(model, max_len=2 ** 20)"
      ],
      "metadata": {
        "id": "nG_XfN2MEJT-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selection of malwares to obfuscate"
      ],
      "metadata": {
        "id": "zzuj3tTrFP3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "N_SAMPLES = 100\n",
        "malware_directory = '/content/test/malware'\n",
        "malware_dest_dir = '/content/malware_to_obfuscate'\n",
        "\n",
        "classification_results = 0\n",
        "if not os.path.exists(malware_dest_dir):\n",
        "  os.mkdir(malware_dest_dir)\n",
        "\n",
        "# search for a file classified as malware (with classification result > 0.5)\n",
        "while len(os.listdir(os.path.join(malware_dest_dir))) < N_SAMPLES:\n",
        "  # input sample that we want to obfuscate\n",
        "  filename = random.choice( os.listdir(malware_directory) )\n",
        "  path = os.path.join(malware_directory,  filename)\n",
        "  with open(path, \"rb\") as file_handle:\n",
        "      code = file_handle.read()\n",
        "      # read the executable as numpy array\n",
        "      x = np.frombuffer(code, dtype=np.uint8)\n",
        "  classification_results = model_wrapper.classify_sample(x)\n",
        "\n",
        "  if classification_results > 0.5:\n",
        "    shutil.copyfile(path, os.path.join(malware_dest_dir, filename))\n",
        "\n",
        "print(len(os.listdir(os.path.join(\"/content/malware_to_obfuscate\"))))"
      ],
      "metadata": {
        "id": "vvFGhgYKFiAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can do a sanity check to verify that malware and benign are correcly classified before the attack."
      ],
      "metadata": {
        "id": "ZZMr5IEiFwB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify if benign are correctly classified\n",
        "benign_path = '/content/test/benign'\n",
        "flag = False\n",
        "for f in os.listdir(benign_path):\n",
        "    with open(os.path.join(benign_path, f), 'rb') as file:\n",
        "        file_bytes = file.read()\n",
        "        if model_wrapper.classify_sample(file_bytes) >= 0.5:\n",
        "            print(\"Benign misclassified: \", f)\n",
        "            os.remove(os.path.join(benign_path, f))\n",
        "            if not os.path.exists(os.path.join(benign_path, f)):\n",
        "                print(\"File removed\")\n",
        "\n",
        "# Verify if malware are correctly\n",
        "malware_path = '/content/malware_to_obfuscate'\n",
        "malware_files = os.listdir(malware_path)\n",
        "for f in malware_files:\n",
        "    with open(os.path.join(malware_path, f), 'rb') as file:\n",
        "        file_bytes = file.read()\n",
        "        if model_wrapper.classify_sample(file_bytes) < 0.5:\n",
        "            print(\"Malware misclassified: \", f)"
      ],
      "metadata": {
        "id": "guSUjwURFwyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAMMA attack"
      ],
      "metadata": {
        "id": "ucPiIbUwG3pJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting attack parameters"
      ],
      "metadata": {
        "id": "14BN2XVkHADs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Section population with how_many = 25\n",
        "section_population_25, _ = create_section_population_from_folder(\n",
        "    benign_path, how_many = 25, sections_to_extract=['.data','.rdata', '.idata', '.rodata'],\n",
        "    cache_file='/content/section_population.pkl')\n",
        "\n",
        "# Section population with how_many = 50\n",
        "section_population_50, _ = create_section_population_from_folder(\n",
        "    benign_path, how_many = 50, sections_to_extract=['.data','.rdata', '.idata', '.rodata'],\n",
        "    cache_file='/content/section_population.pkl')\n",
        "print(\"Section extracted\")\n",
        "\n",
        "# Attack parameters\n",
        "# lambda_values = [10e-3, 10e-5, 10e-7, 10e-9]\n",
        "lambda_values = [10e-3]\n",
        "query_values = [20]\n",
        "POPULATION_SIZE = 20"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OkO4u5wjG81w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining GAMMA attack function"
      ],
      "metadata": {
        "id": "g1no-9dRHc7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ml_pentest.attacks.blackbox.genetic_attack.GAMMA.attack_utils import generate_adv_samples_from_folder\n",
        "\n",
        "def gamma_attack(base_path, section_population):\n",
        "  if not os.path.exists(os.path.join(base_path, 'samples')):\n",
        "      os.makedirs(os.path.join(base_path, 'samples'))\n",
        "  if not os.path.exists(os.path.join(base_path, 'results')):\n",
        "      os.makedirs(os.path.join(base_path, 'results'))\n",
        "\n",
        "  for lambda_value in lambda_values:\n",
        "      if not os.path.isdir(os.path.join(base_path, 'samples',str(lambda_value))):\n",
        "          os.mkdir(os.path.join(base_path, 'samples',str(lambda_value)))\n",
        "      for query_budget in query_values:\n",
        "          destination_folder = os.path.join(base_path, 'samples', str(lambda_value),str(query_budget))\n",
        "          if not os.path.isdir(destination_folder):\n",
        "              os.mkdir(destination_folder)\n",
        "          print(\"Lambda: \", lambda_value, \"Query budget: \", query_budget)\n",
        "          attack = GammaSectionInjection(section_population=section_population, model_wrapper=model_wrapper,\n",
        "                                      population_size=POPULATION_SIZE, lambda_value=lambda_value, iterations=100,\n",
        "                                      debug=False, hard_label=False, query_budget=query_budget,\n",
        "                                      stagnation=5)\n",
        "          result_file = os.path.join(base_path, 'results', 'results_'+str(lambda_value)+'_'+str(query_budget)+'.json')\n",
        "          generate_adv_samples_from_folder(source_folder=malware_path,\n",
        "                                        destination_folder=destination_folder, gamma_attack=attack, model=model_wrapper,result_file=result_file)"
      ],
      "metadata": {
        "id": "T247Ux-FHNBF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GAMMA attack with how_many = 25\n",
        "gamma_attack('/content/attack_results_25', section_population_25)\n",
        "\n",
        "#GAMMA attack with how_many = 50\n",
        "gamma_attack('/content/attack_results_50', section_population_50)"
      ],
      "metadata": {
        "id": "adxKN7VUHaba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the attack"
      ],
      "metadata": {
        "id": "GLO1pq7rIEJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/attack_results_25/results'\n",
        "variant_path = '/content/attack_results_50/results'\n",
        "\n",
        "models = dict()\n",
        "models[\"how_many = 25\"] = base_path\n",
        "models[\"how_many = 50\"] = variant_path"
      ],
      "metadata": {
        "id": "2xILyrcDINkp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ml_pentest.attack_reports.blackbox.genetic_attack.GAMMA.analize_results import compute_mean_times, print_gamma_results, plot_detection_rate, plot_injected_bytes, plot_heatmap, plot_detection_rate_vs_query_budget, plot_avg_injected_bytes_vs_query_budget, plot_gamma_attack\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "malware_files = os.listdir(malware_path)\n",
        "class_results = []\n",
        "\n",
        "for f in malware_files:\n",
        "    with open(os.path.join(malware_path, f), 'rb') as file:\n",
        "        file_bytes = file.read()\n",
        "        class_results.append( model_wrapper.classify_sample(file_bytes) )\n",
        "\n",
        "avg_detection_rate = np.mean(class_results)\n",
        "\n",
        "model_name='MalConv2'\n",
        "\n",
        "print(\"============================ GAMMA Results ============================\")\n",
        "\n",
        "print(\"===== how_many = 25 =====\")\n",
        "for lambda_value in lambda_values:\n",
        "    print_gamma_results(base_path, lambda_value, query_values, avg_detection_rate = avg_detection_rate)\n",
        "\n",
        "print(\"===== how_many = 50 =====\")\n",
        "for lambda_value in lambda_values:\n",
        "    print_gamma_results(variant_path, lambda_value, query_values, avg_detection_rate = avg_detection_rate)\n",
        "\n",
        "\n",
        "save_path = '/content/attack_results/plots'\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# Plotting graphs for how_many = 25\n",
        "plot_detection_rate(base_path, os.path.join(base_path, '25'), query_values, lambda_values, 'detection_rate_gamma.png', model_name=model_name)\n",
        "plot_injected_bytes(base_path, os.path.join(base_path, '25'), query_values, lambda_values, 'GAMMA', 'gamma_injected_bytes.png', model_name=model_name,  x_range_kb=None)\n",
        "plot_heatmap(base_path, os.path.join(base_path, '25'), query_values, lambda_values, 'heatmap.png')\n",
        "\n",
        "# Plotting graphs for how_many = 50\n",
        "plot_detection_rate(base_path, os.path.join(base_path, '50'), query_values, lambda_values, 'detection_rate_gamma.png', model_name=model_name)\n",
        "plot_injected_bytes(base_path, os.path.join(base_path, '50'), query_values, lambda_values, 'GAMMA', 'gamma_injected_bytes.png', model_name=model_name,  x_range_kb=None)\n",
        "plot_heatmap(base_path, os.path.join(base_path, '50'), query_values, lambda_values, 'heatmap.png')\n",
        "\n",
        "# Plotting graphs to compare two attacks\n",
        "plot_gamma_attack(base_path, variant_path, save_path, query_values, lambda_values, 'gamma_attack.png', model_name=model_name)\n",
        "plot_detection_rate_vs_query_budget(models, query_values, lambda_values, save_path, 'detection_vs_query.png')\n",
        "plot_avg_injected_bytes_vs_query_budget(models, query_values, lambda_values, save_path, file_name='avg_injected_bytes_vs_query_budget.png', lower_limit=None, upper_limit=None)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "j7hisO5yIHA1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}