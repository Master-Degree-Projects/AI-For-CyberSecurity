{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting drive"
      ],
      "metadata": {
        "id": "IHSDMXFh4g5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC2NGxBj4jqk",
        "outputId": "df59cb1c-e00d-4776-ad51-41963a265d3c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download datasets"
      ],
      "metadata": {
        "id": "KbE0UOfQ36o3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Downloading training set\n",
        "url = '1-FSnNHp0ZWULfetoYGztn_43TMtxSQaM'\n",
        "gdown.download(id=url, output=\"training_set.tar.gz\")\n",
        "\n",
        "# Downloading validation set\n",
        "url = '1-JLM97nRRcxsU-e1KDvY7_OPQBoxx7H2'\n",
        "gdown.download(id=url, output=\"validation_set.tar.gz\")"
      ],
      "metadata": {
        "id": "RJt76FB8A4qE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataset folders\n",
        "!mkdir -p training validation\n",
        "\n",
        "!tar -zxf '/content/training_set.tar.gz' -C /content/training\n",
        "!rm '/content/training_set.tar.gz'\n",
        "\n",
        "!tar -zxf '/content/validation_set.tar.gz' -C /content/validation\n",
        "!rm '/content/validation_set.tar.gz'"
      ],
      "metadata": {
        "id": "FsET9Xi_4AHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# Downloading SoReL-20M test set\n",
        "url = '1-CNx_k1yEJ-RDC94nXUMlhtc1FQH7lzt'\n",
        "gdown.download(id=url, output=\"test_set.tar.gz\")\n",
        "\n",
        "# Downloading VirusShare test set\n",
        "url = '1Dbb9xNCvL1_HqM9H_Hvq34VvW73cu0n1'\n",
        "gdown.download(id=url, output=\"VirusShareDataset.tar.gz\")"
      ],
      "metadata": {
        "id": "GXxaNn5g4Cff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating test set folders\n",
        "!mkdir -p test test_2\n",
        "\n",
        "!tar -zxf '/content/test_set.tar.gz' -C /content/test\n",
        "!rm '/content/test_set.tar.gz'\n",
        "\n",
        "!tar -zxf '/content/VirusShareDataset.tar.gz' -C /content/test_2\n",
        "!rm '/content/VirusShareDataset.tar.gz'"
      ],
      "metadata": {
        "id": "nbCrKHeX4UC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/training'\n",
        "val_path = '/content/validation'\n",
        "test_path = '/content/test'\n",
        "test_2_path = '/content/test_2'"
      ],
      "metadata": {
        "id": "EH9cm_TJ4bfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies and libraries"
      ],
      "metadata": {
        "id": "9TFJsst54nr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install lief==0.12.0\n",
        "!pip install numpy\n",
        "!pip install deap\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install tqdm\n",
        "!pip install python-magic\n",
        "# Install ML-Pentest Lib\n",
        "!pip install ml-pentest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8UcKwNI4pjk",
        "outputId": "ad4bc34f-2643-49dc-c4f7-ce09b7a23d50"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lief==0.12.0\n",
            "  Downloading lief-0.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lief\n",
            "Successfully installed lief-0.12.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting deap\n",
            "  Downloading deap-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deap) (1.25.2)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.4.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Collecting python-magic\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: python-magic\n",
            "Successfully installed python-magic-0.4.27\n",
            "Collecting ml-pentest\n",
            "  Downloading ml_pentest-0.0.1.tar.gz (57.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ml-pentest\n",
            "  Building wheel for ml-pentest (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-pentest: filename=ml_pentest-0.0.1-py3-none-any.whl size=57887807 sha256=b87abd023dbbf7e223c09997d3fc0b3b77bc05ba9b5a01823d9331e606901c32\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f4/4c/23846e544e3da15cc0a566ea450040ce9181b7d210ef2e41a3\n",
            "Successfully built ml-pentest\n",
            "Installing collected packages: ml-pentest\n",
            "Successfully installed ml-pentest-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ml_pentest.attacks.blackbox.genetic_attack.GAMMA.gamma_section_injection import GammaSectionInjection\n",
        "from ml_pentest.attacks.blackbox.genetic_attack.GAMMA.attack_utils import create_section_population_from_folder\n",
        "from ml_pentest.models.dl_models.raw_bytes_based.malconv2 import MalConv\n",
        "from ml_pentest.models.wrappers.malconv2_wrapper import MalConvWrapper\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import lief\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "wdmaJyqz4ukV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models definition"
      ],
      "metadata": {
        "id": "jHrcYo7A4xWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection\n",
        "Edward Raff, William Fleshman, Richard Zak, Hyrum Anderson and Bobby Filar and Mark Mclean\n",
        "https://arxiv.org/abs/2012.09390\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def drop_zeros_hook(module, grad_input, grad_out):\n",
        "    \"\"\"\n",
        "    This function is used to replace gradients that are all zeros with None\n",
        "    In pyTorch None will not get back-propogated\n",
        "    So we use this as a approximation to saprse BP to avoid redundant and useless work\n",
        "    \"\"\"\n",
        "    grads = []\n",
        "    with torch.no_grad():\n",
        "        for g in grad_input:\n",
        "            if torch.nonzero(g).shape[0] == 0:\n",
        "                grads.append(g.to_sparse())\n",
        "            else:\n",
        "                grads.append(g)\n",
        "\n",
        "    return tuple(grads)\n",
        "\n",
        "\n",
        "class CatMod(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CatMod, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.cat(x, dim=2)\n",
        "\n",
        "\n",
        "class LowMemConvBase(nn.Module):\n",
        "\n",
        "    def __init__(self, chunk_size=65536, overlap=512, min_chunk_size=1024):\n",
        "        \"\"\"\n",
        "        chunk_size: how many bytes at a time to process. Increasing may improve compute efficent, but use more memory. Total memory use will be a function of chunk_size, and not of the length of the input sequence L\n",
        "\n",
        "        overlap: how many bytes of overlap to use between chunks\n",
        "\n",
        "        \"\"\"\n",
        "        super(LowMemConvBase, self).__init__()\n",
        "        self.chunk_size = chunk_size\n",
        "        self.overlap = overlap\n",
        "        self.min_chunk_size = min_chunk_size\n",
        "\n",
        "        #Used for pooling over time in a more efficent way\n",
        "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
        "        self.cat = CatMod()\n",
        "        self.cat.register_backward_hook(drop_zeros_hook)\n",
        "        self.receptive_field = None\n",
        "\n",
        "        #Used to force checkpoint code to behave correctly due to poor design https://discuss.pytorch.org/t/checkpoint-with-no-grad-requiring-inputs-problem/19117/11\n",
        "        self.dummy_tensor = torch.ones(1, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "    def processRange(self, x, **kwargs):\n",
        "        \"\"\"\n",
        "        This method does the work to convert an LongTensor input x of shape (B, L) , where B is the batch size and L is the length of the input. The output of this functoin should be a tensor of (B, C, L), where C is the number of channels, and L is again the input length (though its OK if it got a little shorter due to convs without padding or something).\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def determinRF(self):\n",
        "        \"\"\"\n",
        "        This function evaluates the receptive field & stride of our sub-network.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.receptive_field is not None:\n",
        "            return self.receptive_field, self.stride, self.out_channels\n",
        "\n",
        "        if not hasattr(self, \"device_ids\"):\n",
        "            #We are training with just one device. Lets find out where we should move the data\n",
        "            cur_device = next(self.embd.parameters()).device\n",
        "        else:\n",
        "            cur_device = \"cpu\"\n",
        "\n",
        "        #Lets do a simple binary search to figure out how large our RF is.\n",
        "        #It can't be larger than our chunk size! So use that as upper bound\n",
        "        min_rf = 1\n",
        "        max_rf = self.chunk_size\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            tmp = torch.zeros((1,max_rf)).long().to(cur_device)\n",
        "\n",
        "            while True:\n",
        "                test_size = (min_rf+max_rf)//2\n",
        "                is_valid = True\n",
        "                try:\n",
        "                    self.processRange(tmp[:,0:test_size])\n",
        "                except:\n",
        "                    is_valid = False\n",
        "\n",
        "                if is_valid:\n",
        "                    max_rf = test_size\n",
        "                else:\n",
        "                    min_rf = test_size+1\n",
        "\n",
        "                if max_rf == min_rf:\n",
        "                    self.receptive_field = min_rf\n",
        "                    out_shape = self.processRange(tmp).shape\n",
        "                    self.stride = self.chunk_size//out_shape[2]\n",
        "                    self.out_channels = out_shape[1]\n",
        "                    break\n",
        "\n",
        "\n",
        "        return self.receptive_field, self.stride, self.out_channels\n",
        "\n",
        "\n",
        "    def pool_group(self, *args):\n",
        "        x = self.cat(args)\n",
        "        x = self.pooling(x)\n",
        "        return x\n",
        "\n",
        "    def seq2fix(self, x, pr_args={}):\n",
        "        \"\"\"\n",
        "        Takes in an input LongTensor of (B, L) that will be converted to a fixed length representation (B, C),\n",
        "        where C is the number of channels provided by the base_network given at construction.\n",
        "        \"\"\"\n",
        "\n",
        "        receptive_window, stride, out_channels = self.determinRF()\n",
        "\n",
        "        if x.shape[1] < receptive_window: #This is a tiny input! Pad it out\n",
        "            x = F.pad(x, (0, receptive_window-x.shape[1]), value=0) # 0 is the pad value\n",
        "        batch_size = x.shape[0]\n",
        "        length = x.shape[1]\n",
        "\n",
        "        #Let's go through the input data without gradients first, and find the positions that \"win\"\n",
        "        #the max-pooling. Most of the gradients will be zero, and we don't want to waste valuable\n",
        "        #memory and time computing them.\n",
        "        #Once we know the winners, we will go back and compute the forward activations on JUST\n",
        "        #the subset of positions that won!\n",
        "        winner_values = np.zeros((batch_size, out_channels))-1.0\n",
        "        winner_indices = np.zeros((batch_size, out_channels), dtype=np.int64)\n",
        "\n",
        "        if not hasattr(self, \"device_ids\"):\n",
        "            #We are training with just one device. Lets find out where we should move the data\n",
        "            cur_device = next(self.embd.parameters()).device\n",
        "        else:\n",
        "            cur_device = None\n",
        "\n",
        "        step = self.chunk_size #- self.overlap\n",
        "        start = 0\n",
        "        end = start+step\n",
        "\n",
        "        with torch.no_grad():\n",
        "            while start < end and (end-start) >= max(self.min_chunk_size, receptive_window):\n",
        "                x_sub = x[:,start:end]\n",
        "                if cur_device is not None:\n",
        "                    x_sub = x_sub.to(cur_device)\n",
        "                activs = self.processRange(x_sub.long(), **pr_args)\n",
        "                activ_win, activ_indx = F.max_pool1d(activs, kernel_size=activs.shape[2], return_indices=True)\n",
        "                #We want to remove only last dimension, but if batch size is 1, np.squeeze\n",
        "                #will screw us up and remove first dim too.\n",
        "                #activ_win = np.squeeze(activ_win.cpu().numpy())\n",
        "                #activ_indx = np.squeeze(activ_indx.cpu().numpy())\n",
        "                activ_win = activ_win.cpu().numpy()[:,:,0]\n",
        "                activ_indx = activ_indx.cpu().numpy()[:,:,0]\n",
        "                selected = winner_values < activ_win\n",
        "                winner_indices[selected] = activ_indx[selected]*stride + start\n",
        "                winner_values[selected]  = activ_win[selected]\n",
        "                start = end\n",
        "                end = min(start+step, length)\n",
        "\n",
        "        # Now we know every index that won, we need to compute values and with gradients!\n",
        "\n",
        "        # Find unique winners for every batch\n",
        "        final_indices = [np.unique(winner_indices[b,:]) for b in range(batch_size)]\n",
        "\n",
        "        # Collect inputs that won for each batch\n",
        "        chunk_list = [[x[b:b+1,max(i-receptive_window,0):min(i+receptive_window,length)] for i in final_indices[b]] for b in range(batch_size)]\n",
        "        # Convert to a torch tensor of the bytes\n",
        "        chunk_list = [torch.cat(c, dim=1)[0,:] for c in chunk_list]\n",
        "\n",
        "        # Pad out shorter sequences to the longest one\n",
        "        x_selected = torch.nn.utils.rnn.pad_sequence(chunk_list, batch_first=True)\n",
        "\n",
        "        # Shape is not (B, L). Compute it.\n",
        "        if cur_device is not None:\n",
        "            x_selected = x_selected.to(cur_device)\n",
        "        x_selected = self.processRange(x_selected.long(), **pr_args)\n",
        "        x_selected = self.pooling(x_selected)\n",
        "        x_selected = x_selected.view(x_selected.size(0), -1)\n",
        "\n",
        "        return x_selected\n"
      ],
      "metadata": {
        "id": "i11q4yZv41ph"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MalConv"
      ],
      "metadata": {
        "id": "WQhiPgoY5Sdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MalConv(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, embd_size=8, log_stride=None):\n",
        "        super(MalConv, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        if not log_stride is None:\n",
        "            stride = 2**log_stride\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "        self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "\n",
        "    def processRange(self, x):\n",
        "        x = self.embd(x)\n",
        "        x = torch.transpose(x,-1,-2)\n",
        "\n",
        "        cnn_value = self.conv_1(x)\n",
        "        gating_weight = torch.sigmoid(self.conv_2(x))\n",
        "\n",
        "        x = cnn_value * gating_weight\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "\n",
        "        penult = x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class MalConvML(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, layers=1, embd_size=8, log_stride=None):\n",
        "        super(MalConvML, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        if not log_stride is None:\n",
        "            stride = 2**log_stride\n",
        "\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(embd_size, channels*2, window_size, stride=stride, bias=True)] + [nn.Conv1d(channels, channels*2, window_size, stride=1, bias=True) for i in range(layers-1)])\n",
        "        #one-by-one cons to perform information sharing\n",
        "        self.convs_1 = nn.ModuleList([nn.Conv1d(channels, channels, 1, bias=True) for i in range(layers)])\n",
        "\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "\n",
        "    def processRange(self, x):\n",
        "        x = self.embd(x)\n",
        "        #x = torch.transpose(x,-1,-2)\n",
        "        x = x.permute(0,2,1).contiguous()\n",
        "\n",
        "        for conv_glu, conv_share in zip(self.convs, self.convs_1):\n",
        "            x = F.leaky_relu(conv_share(F.glu(conv_glu(x.contiguous()), dim=1)))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "\n",
        "        penult = x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return x, penult, post_conv"
      ],
      "metadata": {
        "id": "NhXkPvpr5HeJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MalConv2"
      ],
      "metadata": {
        "id": "Z04H3bgc5VJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection\n",
        "Edward Raff, William Fleshman, Richard Zak, Hyrum Anderson and Bobby Filar and Mark Mclean\n",
        "https://arxiv.org/abs/2012.09390\n",
        "\n",
        "Taken from https://github.com/NeuromorphicComputationResearchProgram/MalConv2\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MalConv2(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, embd_size=8, log_stride=None):\n",
        "        super(MalConv2, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        if not log_stride is None:\n",
        "            stride = 2**log_stride\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "        self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "\n",
        "    def processRange(self, x):\n",
        "        x = self.embd(x)\n",
        "        x = torch.transpose(x,-1,-2)\n",
        "\n",
        "        cnn_value = self.conv_1(x)\n",
        "        gating_weight = torch.sigmoid(self.conv_2(x))\n",
        "\n",
        "        x = cnn_value * gating_weight\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "\n",
        "        penult = x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "X0Kwrz115MAC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MalConvGCG"
      ],
      "metadata": {
        "id": "wZ3gpMZM54l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Classifying Sequences of Extreme Length with Constant Memory Applied to Malware Detection\n",
        "Edward Raff, William Fleshman, Richard Zak, Hyrum Anderson and Bobby Filar and Mark Mclean\n",
        "https://arxiv.org/abs/2012.09390\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.checkpoint as checkpoint\n",
        "\n",
        "class MalConvGCG(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=128, window_size=512, stride=512, layers=1, embd_size=8, log_stride=None, low_mem=True):\n",
        "        super(MalConvGCG, self).__init__()\n",
        "        self.low_mem = low_mem\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        if not log_stride is None:\n",
        "            stride = 2**log_stride\n",
        "\n",
        "        self.context_net = MalConvML(out_size=channels, channels=channels, window_size=window_size, stride=stride, layers=layers, embd_size=embd_size)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(embd_size, channels*2, window_size, stride=stride, bias=True)] + [nn.Conv1d(channels, channels*2, window_size, stride=1, bias=True) for i in range(layers-1)])\n",
        "\n",
        "        #These two objs are not used. They were originally present before the F.glu function existed, and then were accidently left in when we switched over. So the state file provided has unusued states in it. They are left in this definition so that there are no issues loading the file that MalConv was trained on.\n",
        "        #If you are going to train from scratch, you can delete these two lines.\n",
        "        #self.convs_1 = nn.ModuleList([nn.Conv1d(channels*2, channels, 1, bias=True) for i in range(layers)])\n",
        "        #self.convs_atn = nn.ModuleList([nn.Conv1d(channels*2, channels, 1, bias=True) for i in range(layers)])\n",
        "\n",
        "        self.linear_atn = nn.ModuleList([nn.Linear(channels, channels) for i in range(layers)])\n",
        "\n",
        "        #one-by-one cons to perform information sharing\n",
        "        self.convs_share = nn.ModuleList([nn.Conv1d(channels, channels, 1, bias=True) for i in range(layers)])\n",
        "\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "\n",
        "    #Over-write the determinRF call to use the base context_net to detemrin RF. We should have the same totla RF, and this will simplify logic significantly.\n",
        "    def determinRF(self):\n",
        "        return self.context_net.determinRF()\n",
        "\n",
        "    def processRange(self, x, gct=None):\n",
        "        if gct is None:\n",
        "            raise Exception(\"No Global Context Given\")\n",
        "\n",
        "        x = self.embd(x)\n",
        "        #x = torch.transpose(x,-1,-2)\n",
        "        x = x.permute(0,2,1)\n",
        "\n",
        "        for conv_glu, linear_cntx, conv_share in zip(self.convs, self.linear_atn, self.convs_share):\n",
        "            x = F.glu(conv_glu(x), dim=1)\n",
        "            x = F.leaky_relu(conv_share(x))\n",
        "            x_len = x.shape[2]\n",
        "            B = x.shape[0]\n",
        "            C = x.shape[1]\n",
        "\n",
        "            sqrt_dim = np.sqrt(x.shape[1])\n",
        "            #we are going to need a version of GCT with a time dimension, which we will adapt as needed to the right length\n",
        "            ctnx = torch.tanh(linear_cntx(gct))\n",
        "\n",
        "            #Size is (B, C), but we need (B, C, 1) to use as a 1d conv filter\n",
        "            ctnx = torch.unsqueeze(ctnx, dim=2)\n",
        "            #roll the batches into the channels\n",
        "            x_tmp = x.view(1,B*C,-1)\n",
        "            #Now we can apply a conv with B groups, so that each batch gets its own context applied only to what was needed\n",
        "            x_tmp = F.conv1d(x_tmp, ctnx, groups=B)\n",
        "            #x_tmp will have a shape of (1, B, L), now we just need to re-order the data back to (B, 1, L)\n",
        "            x_gates = x_tmp.view(B, 1, -1)\n",
        "\n",
        "            #Now we effectively apply σ(x_t^T tanh(W c))\n",
        "            gates = torch.sigmoid( x_gates )\n",
        "            x = x * gates\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.low_mem:\n",
        "            global_context = checkpoint.CheckpointFunction.apply(self.context_net.seq2fix,1, x)\n",
        "        else:\n",
        "            global_context = self.context_net.seq2fix(x)\n",
        "\n",
        "        post_conv = x = self.seq2fix(x, pr_args={'gct':global_context})\n",
        "\n",
        "        penult = x = F.leaky_relu(self.fc_1( x ))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "dbxgBcjl56NR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AvastConv"
      ],
      "metadata": {
        "id": "0V36Bd3z5W8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def vec_bin_array(arr, m=8):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    arr: Numpy array of positive integers\n",
        "    m: Number of bits of each integer to retain\n",
        "\n",
        "    Returns a copy of arr with every element replaced with a bit vector.\n",
        "    Bits encoded as int8's.\n",
        "    \"\"\"\n",
        "    to_str_func = np.vectorize(lambda x: np.binary_repr(x).zfill(m))\n",
        "    strs = to_str_func(arr)\n",
        "    ret = np.zeros(list(arr.shape) + [m], dtype=np.int8)\n",
        "    for bit_ix in range(0, m):\n",
        "        fetch_bit_func = np.vectorize(lambda x: x[bit_ix] == '1')\n",
        "        ret[...,bit_ix] = fetch_bit_func(strs).astype(np.int8)\n",
        "\n",
        "    return (ret*2-1).astype(np.float32)/16\n",
        "\n",
        "class AvastConv(LowMemConvBase):\n",
        "\n",
        "    def __init__(self, out_size=2, channels=48, window_size=32, stride=4, embd_size=8):\n",
        "        super(AvastConv, self).__init__()\n",
        "        self.embd = nn.Embedding(257, embd_size, padding_idx=0)\n",
        "        for i in range(1, 257):\n",
        "            self.embd.weight.data[i,:] = torch.tensor(vec_bin_array(np.asarray([i])))\n",
        "        for param in self.embd.parameters():\n",
        "             param.requires_grad = False\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(8, channels, window_size, stride=stride, bias=True)\n",
        "        self.conv_2 = nn.Conv1d(channels, channels*2, window_size, stride=stride, bias=True)\n",
        "        self.pool = nn.MaxPool1d(4)\n",
        "        self.conv_3 = nn.Conv1d(channels*2, channels*3, window_size//2, stride=stride*2, bias=True)\n",
        "        self.conv_4 = nn.Conv1d(channels*3, channels*4, window_size//2, stride=stride*2, bias=True)\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels*4, channels*4)\n",
        "        self.fc_2 = nn.Linear(channels*4, channels*3)\n",
        "        self.fc_3 = nn.Linear(channels*3, channels*2)\n",
        "        self.fc_4 = nn.Linear(channels*2, out_size)\n",
        "\n",
        "\n",
        "    def processRange(self, x):\n",
        "        # Fixed embedding\n",
        "        with torch.no_grad():\n",
        "            x = self.embd(x)\n",
        "            x = torch.transpose(x,-1,-2)\n",
        "\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = F.relu(self.conv_2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv_3(x))\n",
        "        x = F.relu(self.conv_4(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        post_conv = x = self.seq2fix(x)\n",
        "\n",
        "        x = F.selu(self.fc_1(x))\n",
        "        x = F.selu(self.fc_2(x))\n",
        "        penult = x = F.selu(self.fc_3(x))\n",
        "        x = self.fc_4(x)\n",
        "\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "D1PQDutx5YbO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Procedure"
      ],
      "metadata": {
        "id": "oZPuD36e8OBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom dataloader definition"
      ],
      "metadata": {
        "id": "vS_WHv1S8O_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zlib\n",
        "import torch\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def _seed_all(seed):\n",
        "    os.environ['WANDB_DISABLED'] = 'true'\n",
        "    os.environ['WANDB_MODE'] = 'dryrun'\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.enabled = True\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def decompress_file(input_file_path, max_len=None):\n",
        "    # read the file\n",
        "    with open(input_file_path, 'rb') as f:\n",
        "        compressed_data = f.read()\n",
        "\n",
        "    # decompress the file with zlib\n",
        "    decompressed_data = zlib.decompress(compressed_data)\n",
        "    if max_len:\n",
        "      return decompressed_data[:max_len]\n",
        "    else:\n",
        "      return decompressed_data\n",
        "\n",
        "class BinaryDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Loader for binary files stored on the system.\n",
        "\n",
        "    Note:\n",
        "       - this dataloader assume that the data on the system are organized in such a way that 'benign' is into the file path for benign file only.\n",
        "       - if sorel_20m=True, the malware are assumed to be zipped files.\n",
        "    \"\"\"\n",
        "    def __init__(self, path_list , max_len=2 ** 20, sorel_20m = False, transform = None):\n",
        "\n",
        "        #Tuple (file_path, label, file_size)\n",
        "        self.all_files = []\n",
        "        self.max_len = max_len\n",
        "        self.sorel20m = sorel_20m\n",
        "        self.transform = transform\n",
        "        for path in path_list:\n",
        "            if 'benign' in path:\n",
        "                self.all_files.append(  (path, 0, os.path.getsize(path))  )\n",
        "            else:\n",
        "                self.all_files.append(  (path, 1, os.path.getsize(path))  )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        to_load, y, _ = self.all_files[index]\n",
        "        if not self.sorel20m or (self.sorel20m and y == 0):\n",
        "          #OK, you are not a gziped file. Just read in raw bytes from disk.\n",
        "          with open(to_load, 'rb') as f:\n",
        "              x = f.read(self.max_len)\n",
        "              #Need to use frombuffer b/c its a byte array, otherwise np.asarray will get wonked on trying to convert to ints\n",
        "              #So decode as uint8 (1 byte per value), and then convert\n",
        "              x = np.frombuffer(x, dtype=np.uint8).astype(np.int16)+1 #index 0 will be special padding index\n",
        "        else:\n",
        "              #You are a gziped file. Need to decompress you first.\n",
        "              x = decompress_file(to_load, self.max_len)\n",
        "              x = np.frombuffer(x, dtype=np.uint8).astype(np.int16)+1\n",
        "\n",
        "        if self.transform:\n",
        "          x = self.transform(x)\n",
        "\n",
        "        x = torch.tensor(x)\n",
        "        return x, torch.tensor([y])\n",
        "\n",
        "#We want to handle true variable length\n",
        "#Data loader needs equal length. So use special function to padd all the data in a single batch to be of equal length\n",
        "#to the longest item in the batch\n",
        "def pad_collate_func(batch):\n",
        "    \"\"\"\n",
        "    This should be used as the collate_fn=pad_collate_func for a pytorch DataLoader object in order to pad out files in a batch to the length of the longest item in the batch.\n",
        "    \"\"\"\n",
        "    vecs = [x[0] for x in batch]\n",
        "    labels = [x[1] for x in batch]\n",
        "\n",
        "    x = torch.nn.utils.rnn.pad_sequence(vecs, batch_first=True)\n",
        "    #stack will give us (B, 1), so index [:,0] to get to just (B)\n",
        "    y = torch.stack(labels)[:,0]\n",
        "\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "ZoYkcPQk7LMf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and predict procedure"
      ],
      "metadata": {
        "id": "F8Bm1TNJ8XHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "@torch.no_grad()\n",
        "def predict(model, data_loader, device, criterion,apply_sigmoid=False, to_numpy=True, multiclass = True):\n",
        "    \"\"\"\n",
        "      Predict the target values of the given inputs using a model.\n",
        "\n",
        "      Parameters:\n",
        "      - model (torch.nn.Module): The model to use for prediction.\n",
        "      - data_loader (torch.utils.data.DataLoader): Data loader for the input data.\n",
        "      - device (torch.device): The device to use for computation (CPU or GPU).\n",
        "      - criterion (torch.nn.Module): The loss function to use for evaluation.\n",
        "      - apply_sigmoid (bool, optional): If True, applies sigmoid activation to the output of the model.\n",
        "                                        Default is False.\n",
        "      - to_numpy (bool, optional): If True, converts the true and predicted values to numpy arrays.\n",
        "                                  Default is True.\n",
        "      - multiclass (bool, optional): If True, the problem is multiclass classification.\n",
        "                                    If False, the problem is binary classification.\n",
        "                                    Default is True.\n",
        "\n",
        "      Returns:\n",
        "      - loss (float): The mean loss over the data.\n",
        "      - y_true (torch.Tensor or np.ndarray): The true target values.\n",
        "      - y_pred (torch.Tensor or np.ndarray): The predicted target values.\n",
        "\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    loss=0\n",
        "\n",
        "    for inputs, labels in tqdm(data_loader, leave=False):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if not multiclass:\n",
        "          outputs = torch.round(outputs)\n",
        "          outputs = torch.squeeze(outputs)\n",
        "          labels = labels.float()\n",
        "\n",
        "\n",
        "        loss += criterion(outputs, labels)\n",
        "\n",
        "        if multiclass:\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          y_pred.append(preds)\n",
        "        else:\n",
        "          y_pred.append(outputs)\n",
        "        y_true.append(labels)\n",
        "\n",
        "    y_true = torch.cat(y_true).to(int)\n",
        "    if apply_sigmoid:\n",
        "        y_pred = torch.sigmoid(torch.cat(y_pred))\n",
        "    else:\n",
        "        y_pred = (torch.cat(y_pred) > 0).to(int)\n",
        "        y_pred = y_pred.reshape(-1).to(device)\n",
        "    if to_numpy:\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_pred = y_pred.cpu().numpy()\n",
        "    assert y_true.shape == y_pred.shape\n",
        "    model.train()\n",
        "\n",
        "    return loss/(len(y_true)) , y_true , y_pred\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader, device, criterion,multiclass = True):\n",
        "    \"\"\"\n",
        "      Calculates the accuracy of the model on a given dataset.\n",
        "\n",
        "      Parameters:\n",
        "      model (nn.Module): The model to evaluate accuracy for.\n",
        "      data_loader (DataLoader): The DataLoader for the dataset to evaluate on.\n",
        "      device (torch.device): The device to run the evaluation on.\n",
        "      criterion (nn.Module): The loss function to use for evaluation.\n",
        "      multiclass (bool, optional): Indicates if the model is for multiclass classification or binary. Default is True.\n",
        "\n",
        "      Returns:\n",
        "      float, float: Tuple of average loss and accuracy as percentages (e.g. return value of 50.0, 75.0 indicates an average loss of 50.0 and accuracy of 75%).\n",
        "    \"\"\"\n",
        "    loss, y_true, y_pred = predict(model, data_loader, device,criterion, to_numpy=False, multiclass = multiclass, apply_sigmoid = False)\n",
        "    y_true = y_true.to(device)\n",
        "    y_pred = y_pred.to(device)\n",
        "    return loss, 100 * (y_true == y_pred).to(float).mean().item(), y_true, y_pred\n",
        "\n",
        "\n",
        "\n",
        "def train(model, train_loader, val_loader, device, criterion, save_title, checkpoint_path, patience=3, num_epochs=50, verbose=True):\n",
        "    \"\"\"\n",
        "      Trains a PyTorch model using Adam optimization and early stopping.\n",
        "\n",
        "      Parameters:\n",
        "      - model (torch.nn.Module): a PyTorch model to be trained.\n",
        "      - train_loader (torch.utils.data.DataLoader): a DataLoader containing the training data.\n",
        "      - val_loader (torch.utils.data.DataLoader): a DataLoader containing the validation data.\n",
        "      - device (torch.device): a PyTorch device object, either \"cpu\" or \"cuda\".\n",
        "      - criterion (callable): a loss function to be used for training.\n",
        "      - save_title (str): a string title to be used for saving the trained model.\n",
        "      - patience (int, optional): number of epochs to wait before early stopping. Defaults to 3.\n",
        "      - num_epochs (int, optional): total number of epochs to run the training for. Defaults to 50.\n",
        "      - verbose (bool, optional): whether to print the training and validation loss for each epoch. Defaults to True.\n",
        "\n",
        "      Returns:\n",
        "      None\n",
        "    \"\"\"\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    optimizer = optim.AdamW(model.parameters())\n",
        "    monitor = EarlyStopMonitor(patience)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, factor=0.5, patience=patience\n",
        "    )\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(\"\\nEPOCH {}\".format(epoch))\n",
        "        model.train()\n",
        "        train_loss = run_epoch(model, train_loader, device, criterion, optimizer)\n",
        "        train_loss_history.append(train_loss)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss = run_epoch(model, val_loader, device, criterion)\n",
        "        val_loss_history.append(val_loss)\n",
        "        if verbose:\n",
        "            tqdm.write(\n",
        "                f\"Epoch [{epoch}/{num_epochs}], \"\n",
        "                f\"Train Loss: {train_loss:.4f}, \"\n",
        "                f\"Val Loss: {val_loss:.4f}\"\n",
        "            )\n",
        "        scheduler.step(val_loss)\n",
        "        if monitor.step(val_loss):\n",
        "            break\n",
        "        if len(val_loss_history) == 1 or val_loss < val_loss_history[-2]:\n",
        "            torch.save(\n",
        "                model.state_dict(), os.path.join(checkpoint_path, f\"{save_title}.pt\"),\n",
        "            )\n",
        "\n",
        "\n",
        "def run_epoch(model, data_loader, device, criterion, optimizer=None):\n",
        "    \"\"\"\n",
        "      Run one epoch of the model on a given dataset.\n",
        "\n",
        "      Parameters:\n",
        "      - model (nn.Module): The model to be trained or evaluated.\n",
        "      - data_loader (torch.utils.data.DataLoader): The data loader for the given dataset.\n",
        "      - device (torch.device): The device to run the computation on.\n",
        "      - criterion (function): The loss function to be used.\n",
        "      - optimizer (torch.optim.Optimizer, optional): The optimizer to use for computing gradients during training.\n",
        "        If not provided, the function will run the model in evaluation mode. (default: None)\n",
        "\n",
        "      Returns:\n",
        "      - float: The average loss per sample computed over the dataset.\n",
        "    \"\"\"\n",
        "    total_loss = 0\n",
        "    for inputs, labels in tqdm(data_loader, leave=False):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        labels = labels.unsqueeze(1)\n",
        "        labels = labels.float()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        if optimizer:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "\n",
        "class EarlyStopMonitor:\n",
        "    \"\"\"\n",
        "    Class for early stopping based on the performance metric value.\n",
        "\n",
        "    Args:\n",
        "    - patience (int): Number of consecutive epochs with no improvement before early stopping.\n",
        "    - mode (str, optional): Mode of operation, either 'min' or 'max'. Default is 'min'.\n",
        "\n",
        "    Attributes:\n",
        "    - log (list): Log of performance metrics over epochs.\n",
        "    - mode (str): Mode of operation, either 'min' or 'max'.\n",
        "    - count (int): Counter for consecutive epochs with no improvement.\n",
        "    - patience (int): Number of consecutive epochs with no improvement before early stopping.\n",
        "    \"\"\"\n",
        "    def __init__(self, patience, mode=\"min\"):\n",
        "        # Check if mode is either \"min\" or \"max\"\n",
        "        assert mode in {\"min\", \"max\"}, \"`mode` must be one of 'min' or 'max'\"\n",
        "        self.log = []\n",
        "        self.mode = mode\n",
        "        self.count = 0\n",
        "        self.patience = patience\n",
        "\n",
        "    def step(self, metric):\n",
        "        \"\"\"\n",
        "        Method for updating the log and checking for early stopping.\n",
        "\n",
        "        Args:\n",
        "        - metric (float): The performance metric for the current epoch.\n",
        "\n",
        "        Returns:\n",
        "        - stop (bool): True if early stopping should occur, False otherwise.\n",
        "        \"\"\"\n",
        "        if not self.log:\n",
        "            self.log.append(metric)\n",
        "            return False\n",
        "        # Check if metric is better than previous value\n",
        "        flag = metric > self.log[-1] if self.mode == \"max\" else metric < self.log[-1]\n",
        "        if flag:\n",
        "            self.count += 1\n",
        "        else:\n",
        "            self.count = 0\n",
        "        self.log.append(metric)\n",
        "        return self.count > self.patience"
      ],
      "metadata": {
        "id": "OCoBeuf18YE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data"
      ],
      "metadata": {
        "id": "GZcN4WZB876O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for folder in [train_path, val_path, test_path]:\n",
        "  print(os.path.basename(folder))\n",
        "  print(\"Malware:\\t\",len(os.listdir(os.path.join(folder,'malware'))))\n",
        "  print(\"Benign:\\t\",len(os.listdir(os.path.join(folder,'benign'))),\"\\n\")"
      ],
      "metadata": {
        "id": "xQVCuUh9820T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 2 ** 20 # 1 MB of max lenght\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Load the data\n",
        "x_train = []\n",
        "for folder in os.listdir(train_path):\n",
        "  for filename in os.listdir(os.path.join(train_path, folder)):\n",
        "    if os.path.isfile(os.path.join(train_path, folder ,filename)):\n",
        "      x_train.append(os.path.join(train_path, folder ,filename))\n",
        "\n",
        "\n",
        "x_val = []\n",
        "for folder in os.listdir(val_path):\n",
        "  for filename in os.listdir(os.path.join(val_path, folder)):\n",
        "    if os.path.isfile(os.path.join(val_path, folder ,filename)):\n",
        "      x_val.append(os.path.join(val_path, folder ,filename))\n",
        "\n",
        "x_test = []\n",
        "for folder in os.listdir(test_path):\n",
        "  for filename in os.listdir(os.path.join(test_path, folder)):\n",
        "    if os.path.isfile(os.path.join(test_path, folder, filename)):\n",
        "      x_test.append(os.path.join(test_path, folder, filename))\n",
        "\n",
        "\n",
        "train_dataset = BinaryDataset(path_list=x_train, max_len= MAX_LEN, sorel_20m=False)\n",
        "val_dataset = BinaryDataset(path_list= x_val, max_len= MAX_LEN, sorel_20m=False)\n",
        "test_dataset = BinaryDataset(path_list= x_test, max_len= MAX_LEN, sorel_20m=False)\n",
        "\n",
        "print(\"Train dataset length: \", len(train_dataset))\n",
        "print(\"Val dataset length: \", len(val_dataset))\n",
        "print(\"Test dataset length: \", len(test_dataset))"
      ],
      "metadata": {
        "id": "iopUe-c186-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=pad_collate_func, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=pad_collate_func,  shuffle = False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=pad_collate_func, shuffle = False)"
      ],
      "metadata": {
        "id": "q4F6NxE49Q56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the checkpoint folder to save the best model"
      ],
      "metadata": {
        "id": "8Of1t-sW9fFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p checkpoint"
      ],
      "metadata": {
        "id": "y3IYv9uH9aqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Devide definition"
      ],
      "metadata": {
        "id": "vO3ZtO7W9tgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Device definition\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "M1iyFpJR9vVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {
        "id": "EGhirJq_92ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MalConv2(out_size=1, channels=128, window_size=500, stride=500, embd_size=8, log_stride=None)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "yP0kfn6594t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start training"
      ],
      "metadata": {
        "id": "gj8ucw6Y-Kmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model=model,\n",
        "      criterion=criterion,\n",
        "      val_loader=val_loader,\n",
        "      train_loader=train_loader,\n",
        "      device=device,\n",
        "      patience=3,\n",
        "      num_epochs=20,\n",
        "      verbose=True,\n",
        "      save_title=f'model_name',\n",
        "      checkpoint_path='/content/checkpoint')"
      ],
      "metadata": {
        "id": "ZPjjruS1-NDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing procedure"
      ],
      "metadata": {
        "id": "Hb7iHgxg-ajI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading best model\n",
        "deep_model = MalConv2(out_size=1, channels=128, window_size=500, stride=500, embd_size=8, log_stride=None)\n",
        "deep_model.load_state_dict(torch.load(\"/content/checkpoint/model_name\"), strict=False)\n",
        "deep_model.eval()\n",
        "deep_model.to(device)"
      ],
      "metadata": {
        "id": "Gzd6v8TB-f_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, recall_score, precision_score, f1_score\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, verbose=True):\n",
        "  y_true = y_true.cpu()\n",
        "  y_pred = y_pred.cpu()\n",
        "\n",
        "  cm= confusion_matrix(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred)\n",
        "  recall = recall_score(y_true, y_pred)\n",
        "  f_score = f1_score(y_true, y_pred)\n",
        "\n",
        "  if verbose:\n",
        "    print(f\"Precision: {precision:.5f}\")\n",
        "    print(f\"Recall: {recall:.5f}\")\n",
        "    print(f\"F-score: {f_score:.5f}\")\n",
        "\n",
        "  return cm, precision, recall, f_score"
      ],
      "metadata": {
        "id": "MzSfYm6A_yL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance evaluation on SoReL-20M test set"
      ],
      "metadata": {
        "id": "ObcR3q17-prR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test_sorel, accuracy_test_sorel, y_true_sorel, y_pred_sorel = get_accuracy(deep_model, test_loader, device, criterion, multiclass=False)\n",
        "print(f'Accuracy on test set: {accuracy_test_sorel:.4f}')"
      ],
      "metadata": {
        "id": "Fn6GbGt4-qWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_sorel, precision_sorel, recall_sorel, f_score_sorel = calculate_metrics(y_true_sorel, y_pred_sorel)\n",
        "ConfusionMatrixDisplay(cm_sorel).plot()"
      ],
      "metadata": {
        "id": "FdCuKrdf_bgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance evaluation on VirusShare test set"
      ],
      "metadata": {
        "id": "88uwmXiN--Ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_2 = []\n",
        "for folder in os.listdir(test_2_path):\n",
        "  for filename in os.listdir(os.path.join(test_2_path, folder)):\n",
        "    if os.path.isfile(os.path.join(test_2_path, folder, filename)):\n",
        "      x_test_2.append(os.path.join(test_2_path, folder, filename))\n",
        "\n",
        "test_2_dataset = BinaryDataset(path_list= x_test_2, max_len= MAX_LEN, sorel_20m=False)\n",
        "\n",
        "print(\"Test dataset length: \", len(test_2_dataset))\n",
        "for folder in [test_2_path]:\n",
        "  print(os.path.basename(folder))\n",
        "  print(\"Malware:\\t\",len(os.listdir(os.path.join(folder,'malware'))))\n",
        "  print(\"Benign:\\t\",len(os.listdir(os.path.join(folder,'benign'))),\"\\n\")"
      ],
      "metadata": {
        "id": "MQqnB2fS_98T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_2_loader = DataLoader(test_2_dataset, batch_size=BATCH_SIZE, collate_fn=pad_collate_func, shuffle = False)"
      ],
      "metadata": {
        "id": "FgRQVQ2U_-4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_test_vsd, accuracy_test_vsd, y_true_vsd, y_pred_vsd = get_accuracy(deep_model, test_2_loader, device, criterion, multiclass=False)\n",
        "print(f'Accuracy on test set: {accuracy_test_vsd:.4f}')"
      ],
      "metadata": {
        "id": "_p_cFeGMAI0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm_vsd, precision_vsd, recall_vsd, f_score_vsd = calculate_metrics(y_true_vsd, y_pred_vsd)\n",
        "ConfusionMatrixDisplay(cm_vsd).plot()"
      ],
      "metadata": {
        "id": "Ug3VM5h_AJPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}